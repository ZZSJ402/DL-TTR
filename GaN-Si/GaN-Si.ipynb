{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:08.050247Z",
     "start_time": "2023-07-29T10:19:06.066948Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\nihao\\anaconda3\\lib\\site-packages (1.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nihao\\anaconda3\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\nihao\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: sklearn in c:\\users\\nihao\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy matplotlib pandas sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:08.096123Z",
     "start_time": "2023-07-29T10:19:08.051245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:08.252704Z",
     "start_time": "2023-07-29T10:19:08.205830Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:08.268662Z",
     "start_time": "2023-07-29T10:19:08.253702Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:08.329501Z",
     "start_time": "2023-07-29T10:19:08.269660Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:16.182760Z",
     "start_time": "2023-07-29T10:19:14.987631Z"
    }
   },
   "outputs": [],
   "source": [
    "data = loadmat(r'ST640-GaN-Si-50-generate TTR not shift.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T03:46:59.043190Z",
     "start_time": "2024-01-29T03:46:58.595056Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T03:47:00.568824Z",
     "start_time": "2024-01-29T03:47:00.437097Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f6d279147074>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m're'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "X = data['re']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:16.229635Z",
     "start_time": "2023-07-29T10:19:16.214675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125000, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:19.155343Z",
     "start_time": "2023-07-29T10:19:19.138389Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:19.353814Z",
     "start_time": "2023-07-29T10:19:19.338852Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:19.570374Z",
     "start_time": "2023-07-29T10:19:19.557409Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.transpose(data['re'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:20.095098Z",
     "start_time": "2023-07-29T10:19:20.084127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 125000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:22.445444Z",
     "start_time": "2023-07-29T10:19:22.442451Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:22.646905Z",
     "start_time": "2023-07-29T10:19:22.633940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125000, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:22.923302Z",
     "start_time": "2023-07-29T10:19:22.909337Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X[:,20:299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:24.509361Z",
     "start_time": "2023-07-29T10:19:24.499386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125000, 279)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:47.631863Z",
     "start_time": "2023-07-29T10:19:47.626876Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_2 = np.linspace(10, 250, 50, endpoint=True)\n",
    "layer_3 = np.linspace(20, 200, 50, endpoint=True)\n",
    "layer_4 = np.linspace(50, 250, 50, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:48.125545Z",
     "start_time": "2023-07-29T10:19:48.109588Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.zeros((X.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:48.373031Z",
     "start_time": "2023-07-29T10:19:48.291103Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for l4 in layer_4:\n",
    "    for l3 in layer_3:\n",
    "        for l2 in layer_2:\n",
    "            y[i] = [l4, l3, l2]\n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:19:49.052330Z",
     "start_time": "2023-07-29T10:19:49.045349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125000, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:58:58.657730Z",
     "start_time": "2023-07-29T10:58:58.651746Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:58:59.257267Z",
     "start_time": "2023-07-29T10:58:58.821294Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:58:59.273224Z",
     "start_time": "2023-07-29T10:58:59.258264Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:58:59.425818Z",
     "start_time": "2023-07-29T10:58:59.421828Z"
    }
   },
   "outputs": [],
   "source": [
    "#property = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:58:59.951537Z",
     "start_time": "2023-07-29T10:58:59.924609Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "x_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:59:00.457305Z",
     "start_time": "2023-07-29T10:59:00.421401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Builds dataset with ALL data\n",
    "origin_train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Splits randomly into train and validation datasets\n",
    "train_dataset, val_dataset = random_split(origin_train_dataset, [int(x_train_tensor.shape[0] * 0.9), int(x_train_tensor.shape[0] * 0.1)])\n",
    "\n",
    "# Builds a loader for each dataset to perform mini-batch gradient descent\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=2000)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=2000)\n",
    "\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:59:01.660390Z",
     "start_time": "2023-07-29T10:59:01.657399Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:59:02.230999Z",
     "start_time": "2023-07-29T10:59:02.214043Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(X.shape[1])\n",
    "        self.fc1 = nn.Linear(X.shape[1], 100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        self.fc4 = nn.Linear(10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = torch.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:59:03.205531Z",
     "start_time": "2023-07-29T10:59:03.199548Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:59:03.927757Z",
     "start_time": "2023-07-29T10:59:03.923768Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:07:47.394254Z",
     "start_time": "2023-07-29T11:07:47.388270Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:07:47.562804Z",
     "start_time": "2023-07-29T11:07:47.551835Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "        yh = model(x)\n",
    "        #yh = torch.reshape(yh, (-1,))\n",
    "        loss = loss_fn(y, yh)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:07:47.715396Z",
     "start_time": "2023-07-29T11:07:47.700437Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "train_step = make_train_step(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:07:47.840064Z",
     "start_time": "2023-07-29T11:07:47.834080Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (bn1): BatchNorm1d(279, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=279, out_features=100, bias=True)\n",
       "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (fc4): Linear(in_features=10, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:09:33.792689Z",
     "start_time": "2023-07-29T11:07:48.020582Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training loss: 20686.91609\t Validation loss: 20327.73926\n",
      "[2] Training loss: 20117.33214\t Validation loss: 19649.30729\n",
      "[3] Training loss: 19327.03552\t Validation loss: 18712.97038\n",
      "[4] Training loss: 18254.93327\t Validation loss: 17498.78385\n",
      "[5] Training loss: 16918.61514\t Validation loss: 16030.13688\n",
      "[6] Training loss: 15433.56386\t Validation loss: 14579.24593\n",
      "[7] Training loss: 13937.99161\t Validation loss: 13114.66960\n",
      "[8] Training loss: 12418.70258\t Validation loss: 11712.78499\n",
      "[9] Training loss: 11132.27228\t Validation loss: 10621.22705\n",
      "[10] Training loss: 10156.11350\t Validation loss: 9704.74235\n",
      "[11] Training loss: 9434.24398\t Validation loss: 9150.21305\n",
      "[12] Training loss: 8960.26666\t Validation loss: 8707.86507\n",
      "[13] Training loss: 8666.42636\t Validation loss: 8478.22005\n",
      "[14] Training loss: 8517.48297\t Validation loss: 8374.77539\n",
      "[15] Training loss: 8432.60787\t Validation loss: 8330.54093\n",
      "[16] Training loss: 8386.04621\t Validation loss: 8272.25903\n",
      "[17] Training loss: 8336.53800\t Validation loss: 8217.85547\n",
      "[18] Training loss: 8260.60126\t Validation loss: 8111.27922\n",
      "[19] Training loss: 8135.05490\t Validation loss: 8007.72534\n",
      "[20] Training loss: 8024.59314\t Validation loss: 7880.99479\n",
      "[21] Training loss: 7913.04321\t Validation loss: 7785.88208\n",
      "[22] Training loss: 7812.54061\t Validation loss: 7681.94735\n",
      "[23] Training loss: 7725.23475\t Validation loss: 7590.83162\n",
      "[24] Training loss: 7637.92933\t Validation loss: 7508.19206\n",
      "[25] Training loss: 7567.37678\t Validation loss: 7445.50187\n",
      "[26] Training loss: 7514.71751\t Validation loss: 7397.05737\n",
      "[27] Training loss: 7473.70095\t Validation loss: 7364.14860\n",
      "[28] Training loss: 7440.68762\t Validation loss: 7337.44963\n",
      "[29] Training loss: 7418.09467\t Validation loss: 7318.69954\n",
      "[30] Training loss: 7401.05582\t Validation loss: 7303.52775\n",
      "[31] Training loss: 7387.86856\t Validation loss: 7292.24463\n",
      "[32] Training loss: 7377.83158\t Validation loss: 7281.84106\n",
      "[33] Training loss: 7370.67339\t Validation loss: 7275.22843\n",
      "[34] Training loss: 7364.97824\t Validation loss: 7268.61768\n",
      "[35] Training loss: 7360.49637\t Validation loss: 7264.26270\n",
      "[36] Training loss: 7355.33776\t Validation loss: 7263.79150\n",
      "[37] Training loss: 7351.81893\t Validation loss: 7256.69564\n",
      "[38] Training loss: 7350.01103\t Validation loss: 7255.54899\n",
      "[39] Training loss: 7347.85804\t Validation loss: 7256.10083\n",
      "[40] Training loss: 7345.48402\t Validation loss: 7251.74194\n",
      "[41] Training loss: 7344.65731\t Validation loss: 7252.07983\n",
      "[42] Training loss: 7343.01234\t Validation loss: 7248.57210\n",
      "[43] Training loss: 7342.11146\t Validation loss: 7247.74642\n",
      "[44] Training loss: 7342.85907\t Validation loss: 7250.10449\n",
      "[45] Training loss: 7342.32094\t Validation loss: 7249.01636\n",
      "[46] Training loss: 7341.95333\t Validation loss: 7249.25920\n",
      "[47] Training loss: 7341.74663\t Validation loss: 7251.15845\n",
      "[48] Training loss: 6522.44532\t Validation loss: 5014.87337\n",
      "[49] Training loss: 4099.75494\t Validation loss: 3206.57865\n",
      "[50] Training loss: 2668.86456\t Validation loss: 2121.71647\n",
      "[51] Training loss: 1823.65225\t Validation loss: 1581.55772\n",
      "[52] Training loss: 1409.65651\t Validation loss: 1260.69472\n",
      "[53] Training loss: 984.55183\t Validation loss: 711.18801\n",
      "[54] Training loss: 495.66244\t Validation loss: 322.00650\n",
      "[55] Training loss: 232.24014\t Validation loss: 166.13827\n",
      "[56] Training loss: 126.61471\t Validation loss: 100.90968\n",
      "[57] Training loss: 81.47393\t Validation loss: 67.31190\n",
      "[58] Training loss: 59.97409\t Validation loss: 52.11615\n",
      "[59] Training loss: 48.92260\t Validation loss: 43.13206\n",
      "[60] Training loss: 42.79590\t Validation loss: 36.14852\n",
      "[61] Training loss: 38.91683\t Validation loss: 33.46900\n",
      "[62] Training loss: 35.98804\t Validation loss: 31.03754\n",
      "[63] Training loss: 33.44055\t Validation loss: 28.97819\n",
      "[64] Training loss: 31.52172\t Validation loss: 27.69790\n",
      "[65] Training loss: 30.17892\t Validation loss: 26.74966\n",
      "[66] Training loss: 29.12917\t Validation loss: 25.70269\n",
      "[67] Training loss: 28.23585\t Validation loss: 24.86738\n",
      "[68] Training loss: 27.45997\t Validation loss: 24.26542\n",
      "[69] Training loss: 26.72449\t Validation loss: 23.75493\n",
      "[70] Training loss: 26.03620\t Validation loss: 23.38517\n",
      "[71] Training loss: 25.42887\t Validation loss: 23.07248\n",
      "[72] Training loss: 24.88048\t Validation loss: 22.77378\n",
      "[73] Training loss: 24.46318\t Validation loss: 22.93020\n",
      "[74] Training loss: 24.22810\t Validation loss: 23.96950\n",
      "[75] Training loss: 23.97324\t Validation loss: 23.75107\n",
      "[76] Training loss: 23.48947\t Validation loss: 23.04467\n",
      "[77] Training loss: 23.04990\t Validation loss: 22.46775\n",
      "[78] Training loss: 22.65064\t Validation loss: 22.01548\n",
      "[79] Training loss: 22.28322\t Validation loss: 21.72974\n",
      "[80] Training loss: 21.93615\t Validation loss: 21.40769\n"
     ]
    }
   ],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    batch_losses = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        batch_losses.append(loss)\n",
    "    training_loss = np.mean(batch_losses)\n",
    "    training_losses.append(training_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            model.eval()\n",
    "            yh = model(x_val)\n",
    "            #yh = torch.reshape(yh, (-1,))\n",
    "            val_loss = loss_fn(y_val, yh).item()\n",
    "            val_losses.append(val_loss)\n",
    "        validation_loss = np.mean(val_losses)\n",
    "        validation_losses.append(validation_loss)\n",
    "\n",
    "    print(f\"[{epoch+1}] Training loss: {training_loss:.5f}\\t Validation loss: {validation_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:09:33.807649Z",
     "start_time": "2023-07-29T11:09:33.793686Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:09:33.823606Z",
     "start_time": "2023-07-29T11:09:33.809644Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return torch.mean(torch.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:09:33.839563Z",
     "start_time": "2023-07-29T11:09:33.824604Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_tensor = x_test_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "y_pred = model(x_test_tensor).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:09:33.855521Z",
     "start_time": "2023-07-29T11:09:33.840561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.1191, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_loss = loss_fn(y_test_tensor, y_pred)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:09:33.903393Z",
     "start_time": "2023-07-29T11:09:33.894417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of absolute percentage error for L1: 3.85%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mean of absolute percentage error: {mean_absolute_percentage_error(y_test_tensor.cpu(), y_pred.cpu()):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:26:22.923580Z",
     "start_time": "2023-07-29T10:26:22.911610Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:26:23.127035Z",
     "start_time": "2023-07-29T10:26:23.084150Z"
    }
   },
   "outputs": [],
   "source": [
    "case1 = pd.read_csv('20230220036.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:26:23.609748Z",
     "start_time": "2023-07-29T10:26:23.592793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T10:26:23.965936Z",
     "start_time": "2023-07-29T10:26:23.946989Z"
    }
   },
   "outputs": [],
   "source": [
    "case1= np.array(case1)\n",
    "case1=case1[:,20:299]\n",
    "case1_tensor = torch.from_numpy(case1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:09:38.294472Z",
     "start_time": "2023-07-29T11:09:38.282504Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred_1 = model(case1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:09:38.507902Z",
     "start_time": "2023-07-29T11:09:38.498927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[171.9459,  70.7058, 134.6853]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T11:09:59.600248Z",
     "start_time": "2023-07-29T11:09:59.589278Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model,'GaN-Si140-50^3-12-8000-BATCH2000-EPO80-lr0.01-20230729.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T12:58:59.437715Z",
     "start_time": "2023-03-16T12:58:59.418759Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GaN-SiC300-12.5w-108-299-BATCH2000-EPO100-lr0.005-20230316.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-413-075accf8e753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAU_SIMODEL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GaN-SiC300-12.5w-108-299-BATCH2000-EPO100-lr0.005-20230316.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GaN-SiC300-12.5w-108-299-BATCH2000-EPO100-lr0.005-20230316.pth'"
     ]
    }
   ],
   "source": [
    "AU_SIMODEL = torch.load('GaN-SiC300-12.5w-108-299-BATCH2000-EPO100-lr0.005-20230316.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case1 = pd.read_csv('GaN160+GaN100+TBC1+SiC300.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2 = AU_SIMODEL(case1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5689],\n",
       "        [0.5230],\n",
       "        [0.5014],\n",
       "        [0.3863],\n",
       "        [0.5495]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Au-Gan-SiC100-6-1500-generate TTR not shift"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
