{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:22.571603Z",
     "start_time": "2023-02-23T12:25:20.863664Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\nihao\\anaconda3\\lib\\site-packages (1.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nihao\\anaconda3\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\nihao\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: sklearn in c:\\users\\nihao\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\nihao\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy matplotlib pandas sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:22.618371Z",
     "start_time": "2023-02-23T12:25:22.572605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:23.049856Z",
     "start_time": "2023-02-23T12:25:22.953683Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:23.543832Z",
     "start_time": "2023-02-23T12:25:23.504136Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:23.743679Z",
     "start_time": "2023-02-23T12:25:23.739691Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:55.324862Z",
     "start_time": "2023-02-23T12:25:55.154014Z"
    }
   },
   "outputs": [],
   "source": [
    "data = loadmat(r'Al-Sa-weidianzi-generateTTRnotshift.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = scipy.io.loadmat('re20220415.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:57.333606Z",
     "start_time": "2023-02-23T12:25:57.320636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51874289 0.55444985 0.59019769 ... 0.0166075  0.01644659 0.01628653]\n",
      " [0.51880569 0.55451583 0.59026658 ... 0.01648318 0.01632349 0.01616412]\n",
      " [0.51886721 0.55458046 0.59033406 ... 0.01636108 0.01620214 0.01604406]\n",
      " ...\n",
      " [0.74210795 0.77924699 0.81446449 ... 0.02428921 0.02404812 0.02380834]\n",
      " [0.74243714 0.77956991 0.81477718 ... 0.02423477 0.0239936  0.02375427]\n",
      " [0.74276444 0.77989096 0.81508806 ... 0.02418054 0.02393981 0.02370079]]\n"
     ]
    }
   ],
   "source": [
    "print(data['re'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:58.171825Z",
     "start_time": "2023-02-23T12:25:58.155864Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:58.387308Z",
     "start_time": "2023-02-23T12:25:58.372339Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:58.633497Z",
     "start_time": "2023-02-23T12:25:58.627496Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.transpose(data['re'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:58.976203Z",
     "start_time": "2023-02-23T12:25:58.968221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 10000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:59.393897Z",
     "start_time": "2023-02-23T12:25:59.387865Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:25:59.887638Z",
     "start_time": "2023-02-23T12:25:59.881687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:15.434103Z",
     "start_time": "2023-02-23T12:26:15.425124Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_1 = np.linspace(250, 500, 100, endpoint=True)\n",
    "layer_4 = np.linspace(0.1, 1.5, 100, endpoint=True)\n",
    "layer_2 = layer_4*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:16.038709Z",
     "start_time": "2023-02-23T12:26:16.027737Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.zeros((X.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:16.439766Z",
     "start_time": "2023-02-23T12:26:16.419960Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for l2 in layer_2:\n",
    "    for l1 in layer_1:\n",
    "            y[i] = [ l2, l1]\n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:17.755051Z",
     "start_time": "2023-02-23T12:26:17.746071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:22.410354Z",
     "start_time": "2023-02-23T12:26:21.870523Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:22.442265Z",
     "start_time": "2023-02-23T12:26:22.411316Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:23.122258Z",
     "start_time": "2023-02-23T12:26:22.703994Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:23.353978Z",
     "start_time": "2023-02-23T12:26:23.345999Z"
    }
   },
   "outputs": [],
   "source": [
    "#property = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:23.927394Z",
     "start_time": "2023-02-23T12:26:23.918423Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(X_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "x_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:25.597441Z",
     "start_time": "2023-02-23T12:26:25.590459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Builds dataset with ALL data\n",
    "origin_train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Splits randomly into train and validation datasets\n",
    "train_dataset, val_dataset = random_split(origin_train_dataset, [int(x_train_tensor.shape[0] * 0.9), int(x_train_tensor.shape[0] * 0.1)])\n",
    "\n",
    "# Builds a loader for each dataset to perform mini-batch gradient descent\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=2000)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=2000)\n",
    "\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:26.154686Z",
     "start_time": "2023-02-23T12:26:26.149700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:27.559410Z",
     "start_time": "2023-02-23T12:26:27.542207Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(X.shape[1])\n",
    "        self.fc1 = nn.Linear(X.shape[1], 100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        self.fc4 = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = torch.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:27.977303Z",
     "start_time": "2023-02-23T12:26:27.964279Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:28.178502Z",
     "start_time": "2023-02-23T12:26:28.169522Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:28.454694Z",
     "start_time": "2023-02-23T12:26:28.451703Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:30.091985Z",
     "start_time": "2023-02-23T12:26:30.076028Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        model.train()\n",
    "        yh = model(x)\n",
    "        #yh = torch.reshape(yh, (-1,))\n",
    "        loss = loss_fn(y, yh)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        return loss.item()\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:30.293016Z",
     "start_time": "2023-02-23T12:26:30.286032Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "train_step = make_train_step(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:30.539377Z",
     "start_time": "2023-02-23T12:26:30.531395Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (fc4): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:26:52.307226Z",
     "start_time": "2023-02-23T12:26:30.929061Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Training loss: 667.19224\t Validation loss: 680.97479\n",
      "[2] Training loss: 637.11033\t Validation loss: 657.40625\n",
      "[3] Training loss: 599.71395\t Validation loss: 607.15778\n",
      "[4] Training loss: 554.35172\t Validation loss: 544.28241\n",
      "[5] Training loss: 502.93427\t Validation loss: 484.82651\n",
      "[6] Training loss: 448.33002\t Validation loss: 428.24625\n",
      "[7] Training loss: 393.58810\t Validation loss: 379.67892\n",
      "[8] Training loss: 340.43217\t Validation loss: 325.32086\n",
      "[9] Training loss: 292.26480\t Validation loss: 281.50204\n",
      "[10] Training loss: 245.66990\t Validation loss: 231.21095\n",
      "[11] Training loss: 201.21704\t Validation loss: 190.45624\n",
      "[12] Training loss: 160.51183\t Validation loss: 140.23630\n",
      "[13] Training loss: 125.75201\t Validation loss: 111.24151\n",
      "[14] Training loss: 92.49930\t Validation loss: 74.91708\n",
      "[15] Training loss: 73.49213\t Validation loss: 62.28900\n",
      "[16] Training loss: 56.45134\t Validation loss: 50.37185\n",
      "[17] Training loss: 50.95397\t Validation loss: 45.55236\n",
      "[18] Training loss: 44.31198\t Validation loss: 35.08241\n",
      "[19] Training loss: 31.97403\t Validation loss: 29.34094\n",
      "[20] Training loss: 27.11042\t Validation loss: 21.78391\n",
      "[21] Training loss: 23.49261\t Validation loss: 25.57276\n",
      "[22] Training loss: 22.31536\t Validation loss: 33.61245\n",
      "[23] Training loss: 18.89052\t Validation loss: 14.96434\n",
      "[24] Training loss: 18.07504\t Validation loss: 20.56159\n",
      "[25] Training loss: 18.89507\t Validation loss: 16.24284\n",
      "[26] Training loss: 18.25417\t Validation loss: 14.23958\n",
      "[27] Training loss: 17.13625\t Validation loss: 15.46737\n",
      "[28] Training loss: 16.18431\t Validation loss: 15.57406\n",
      "[29] Training loss: 17.03192\t Validation loss: 15.93202\n",
      "[30] Training loss: 15.58883\t Validation loss: 14.02693\n",
      "[31] Training loss: 14.83213\t Validation loss: 14.41883\n",
      "[32] Training loss: 14.83993\t Validation loss: 13.06703\n",
      "[33] Training loss: 15.03533\t Validation loss: 13.79521\n",
      "[34] Training loss: 14.73238\t Validation loss: 14.74107\n",
      "[35] Training loss: 13.49319\t Validation loss: 14.92587\n",
      "[36] Training loss: 14.40816\t Validation loss: 14.46169\n",
      "[37] Training loss: 13.71023\t Validation loss: 14.07953\n",
      "[38] Training loss: 12.74532\t Validation loss: 13.58688\n",
      "[39] Training loss: 12.82783\t Validation loss: 12.55502\n",
      "[40] Training loss: 12.29593\t Validation loss: 12.34618\n",
      "[41] Training loss: 11.66449\t Validation loss: 10.77867\n",
      "[42] Training loss: 10.65016\t Validation loss: 8.84700\n",
      "[43] Training loss: 9.85835\t Validation loss: 8.27756\n",
      "[44] Training loss: 8.35521\t Validation loss: 6.05203\n",
      "[45] Training loss: 6.69858\t Validation loss: 4.45440\n",
      "[46] Training loss: 5.45161\t Validation loss: 4.65602\n",
      "[47] Training loss: 4.20374\t Validation loss: 3.86345\n",
      "[48] Training loss: 3.58968\t Validation loss: 3.62949\n",
      "[49] Training loss: 3.59790\t Validation loss: 2.74455\n",
      "[50] Training loss: 3.48775\t Validation loss: 3.00147\n",
      "[51] Training loss: 3.60348\t Validation loss: 3.22480\n",
      "[52] Training loss: 3.23779\t Validation loss: 2.82227\n",
      "[53] Training loss: 2.79865\t Validation loss: 3.00902\n",
      "[54] Training loss: 2.00974\t Validation loss: 2.19379\n",
      "[55] Training loss: 1.94396\t Validation loss: 2.75289\n",
      "[56] Training loss: 1.97544\t Validation loss: 2.70161\n",
      "[57] Training loss: 1.78856\t Validation loss: 1.44739\n",
      "[58] Training loss: 1.50362\t Validation loss: 1.21693\n",
      "[59] Training loss: 1.98559\t Validation loss: 1.58632\n",
      "[60] Training loss: 1.84814\t Validation loss: 1.62517\n",
      "[61] Training loss: 1.37707\t Validation loss: 1.71653\n",
      "[62] Training loss: 1.62623\t Validation loss: 1.38602\n",
      "[63] Training loss: 1.45118\t Validation loss: 1.67870\n",
      "[64] Training loss: 1.51196\t Validation loss: 1.28781\n",
      "[65] Training loss: 1.32839\t Validation loss: 0.81569\n",
      "[66] Training loss: 1.26968\t Validation loss: 1.65130\n",
      "[67] Training loss: 1.29413\t Validation loss: 1.67090\n",
      "[68] Training loss: 1.41234\t Validation loss: 1.24447\n",
      "[69] Training loss: 1.21455\t Validation loss: 0.97325\n",
      "[70] Training loss: 1.25034\t Validation loss: 0.79987\n",
      "[71] Training loss: 1.08695\t Validation loss: 0.66443\n",
      "[72] Training loss: 0.91205\t Validation loss: 0.64590\n",
      "[73] Training loss: 1.00389\t Validation loss: 0.78751\n",
      "[74] Training loss: 1.05270\t Validation loss: 0.78470\n",
      "[75] Training loss: 0.93128\t Validation loss: 1.37319\n",
      "[76] Training loss: 1.25315\t Validation loss: 1.44410\n",
      "[77] Training loss: 0.97288\t Validation loss: 0.74763\n",
      "[78] Training loss: 0.87493\t Validation loss: 0.59206\n",
      "[79] Training loss: 0.90940\t Validation loss: 0.53605\n",
      "[80] Training loss: 0.64164\t Validation loss: 0.61499\n",
      "[81] Training loss: 0.79144\t Validation loss: 0.63350\n",
      "[82] Training loss: 0.72253\t Validation loss: 0.94416\n",
      "[83] Training loss: 0.59691\t Validation loss: 0.65171\n",
      "[84] Training loss: 0.53257\t Validation loss: 0.36956\n",
      "[85] Training loss: 0.63900\t Validation loss: 0.51119\n",
      "[86] Training loss: 0.56696\t Validation loss: 0.55444\n",
      "[87] Training loss: 0.53377\t Validation loss: 0.45772\n",
      "[88] Training loss: 0.51080\t Validation loss: 0.40421\n",
      "[89] Training loss: 0.51290\t Validation loss: 0.48019\n",
      "[90] Training loss: 0.48167\t Validation loss: 0.29703\n",
      "[91] Training loss: 0.56936\t Validation loss: 0.48039\n",
      "[92] Training loss: 0.49852\t Validation loss: 0.40205\n",
      "[93] Training loss: 0.40229\t Validation loss: 0.25893\n",
      "[94] Training loss: 0.55697\t Validation loss: 0.87945\n",
      "[95] Training loss: 0.46745\t Validation loss: 0.35308\n",
      "[96] Training loss: 0.35657\t Validation loss: 0.30530\n",
      "[97] Training loss: 0.54085\t Validation loss: 1.80735\n",
      "[98] Training loss: 0.72427\t Validation loss: 1.78326\n",
      "[99] Training loss: 1.07447\t Validation loss: 2.10506\n",
      "[100] Training loss: 0.85210\t Validation loss: 1.04985\n",
      "[101] Training loss: 0.63997\t Validation loss: 0.96011\n",
      "[102] Training loss: 0.55943\t Validation loss: 0.44873\n",
      "[103] Training loss: 0.42698\t Validation loss: 0.66397\n",
      "[104] Training loss: 0.43593\t Validation loss: 0.25320\n",
      "[105] Training loss: 0.44648\t Validation loss: 0.65873\n",
      "[106] Training loss: 0.59990\t Validation loss: 1.16305\n",
      "[107] Training loss: 0.70665\t Validation loss: 0.44245\n",
      "[108] Training loss: 0.36651\t Validation loss: 0.32654\n",
      "[109] Training loss: 0.43928\t Validation loss: 0.59652\n",
      "[110] Training loss: 0.41965\t Validation loss: 0.32920\n",
      "[111] Training loss: 0.48807\t Validation loss: 1.03534\n",
      "[112] Training loss: 0.36782\t Validation loss: 0.49480\n",
      "[113] Training loss: 0.30008\t Validation loss: 0.16333\n",
      "[114] Training loss: 0.36652\t Validation loss: 0.29551\n",
      "[115] Training loss: 0.41353\t Validation loss: 0.44817\n",
      "[116] Training loss: 0.47355\t Validation loss: 0.83904\n",
      "[117] Training loss: 0.43172\t Validation loss: 0.55099\n",
      "[118] Training loss: 0.51301\t Validation loss: 0.56661\n",
      "[119] Training loss: 0.46228\t Validation loss: 0.84986\n",
      "[120] Training loss: 0.36658\t Validation loss: 0.31975\n",
      "[121] Training loss: 0.28568\t Validation loss: 0.15729\n",
      "[122] Training loss: 0.39994\t Validation loss: 0.29074\n",
      "[123] Training loss: 0.78933\t Validation loss: 0.95015\n",
      "[124] Training loss: 1.37855\t Validation loss: 1.76909\n",
      "[125] Training loss: 0.85594\t Validation loss: 0.81758\n",
      "[126] Training loss: 0.52268\t Validation loss: 0.46136\n",
      "[127] Training loss: 0.46860\t Validation loss: 1.33905\n",
      "[128] Training loss: 0.48592\t Validation loss: 0.90577\n",
      "[129] Training loss: 0.45786\t Validation loss: 0.30469\n",
      "[130] Training loss: 0.34898\t Validation loss: 0.75311\n",
      "[131] Training loss: 0.35750\t Validation loss: 0.79103\n",
      "[132] Training loss: 0.27267\t Validation loss: 0.19010\n",
      "[133] Training loss: 0.37530\t Validation loss: 0.45285\n",
      "[134] Training loss: 0.37238\t Validation loss: 0.79054\n",
      "[135] Training loss: 0.31999\t Validation loss: 0.48383\n",
      "[136] Training loss: 0.28243\t Validation loss: 0.13513\n",
      "[137] Training loss: 0.32134\t Validation loss: 0.46174\n",
      "[138] Training loss: 0.30307\t Validation loss: 0.41445\n",
      "[139] Training loss: 0.35004\t Validation loss: 0.34705\n",
      "[140] Training loss: 0.46058\t Validation loss: 0.37951\n",
      "[141] Training loss: 0.35874\t Validation loss: 0.28215\n",
      "[142] Training loss: 0.37234\t Validation loss: 0.52958\n",
      "[143] Training loss: 0.37454\t Validation loss: 0.30958\n",
      "[144] Training loss: 0.35047\t Validation loss: 0.58540\n",
      "[145] Training loss: 0.25718\t Validation loss: 0.55287\n",
      "[146] Training loss: 0.30940\t Validation loss: 0.41096\n",
      "[147] Training loss: 0.43271\t Validation loss: 0.70630\n",
      "[148] Training loss: 0.36061\t Validation loss: 0.38403\n",
      "[149] Training loss: 0.27782\t Validation loss: 0.61325\n",
      "[150] Training loss: 0.24093\t Validation loss: 0.15228\n",
      "[151] Training loss: 0.28849\t Validation loss: 0.53139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152] Training loss: 0.34051\t Validation loss: 0.14648\n",
      "[153] Training loss: 0.50300\t Validation loss: 0.48502\n",
      "[154] Training loss: 0.42649\t Validation loss: 1.92804\n",
      "[155] Training loss: 0.54733\t Validation loss: 0.90034\n",
      "[156] Training loss: 0.43373\t Validation loss: 0.24133\n",
      "[157] Training loss: 0.52626\t Validation loss: 0.68039\n",
      "[158] Training loss: 0.43917\t Validation loss: 0.45761\n",
      "[159] Training loss: 0.31187\t Validation loss: 0.49063\n",
      "[160] Training loss: 0.38038\t Validation loss: 0.35886\n",
      "[161] Training loss: 0.36370\t Validation loss: 0.72626\n",
      "[162] Training loss: 0.35470\t Validation loss: 0.54933\n",
      "[163] Training loss: 0.31655\t Validation loss: 0.33894\n",
      "[164] Training loss: 0.30605\t Validation loss: 0.14047\n",
      "[165] Training loss: 0.49062\t Validation loss: 0.84296\n",
      "[166] Training loss: 0.65160\t Validation loss: 0.44456\n",
      "[167] Training loss: 0.35332\t Validation loss: 0.44865\n",
      "[168] Training loss: 0.41996\t Validation loss: 0.28210\n",
      "[169] Training loss: 0.21726\t Validation loss: 0.07942\n",
      "[170] Training loss: 0.26170\t Validation loss: 0.55329\n",
      "[171] Training loss: 0.23961\t Validation loss: 0.27120\n",
      "[172] Training loss: 0.26591\t Validation loss: 0.13269\n",
      "[173] Training loss: 0.37919\t Validation loss: 0.40113\n",
      "[174] Training loss: 0.29712\t Validation loss: 0.78367\n",
      "[175] Training loss: 0.29851\t Validation loss: 0.45453\n",
      "[176] Training loss: 0.32055\t Validation loss: 0.13315\n",
      "[177] Training loss: 0.31200\t Validation loss: 0.32200\n",
      "[178] Training loss: 0.22842\t Validation loss: 0.19844\n",
      "[179] Training loss: 0.23468\t Validation loss: 0.28321\n",
      "[180] Training loss: 0.33586\t Validation loss: 0.28317\n",
      "[181] Training loss: 0.30924\t Validation loss: 0.27138\n",
      "[182] Training loss: 0.18390\t Validation loss: 0.15414\n",
      "[183] Training loss: 0.27065\t Validation loss: 0.44653\n",
      "[184] Training loss: 0.31858\t Validation loss: 0.14107\n",
      "[185] Training loss: 0.35299\t Validation loss: 0.30891\n",
      "[186] Training loss: 0.29729\t Validation loss: 1.69525\n",
      "[187] Training loss: 0.32416\t Validation loss: 0.12165\n",
      "[188] Training loss: 0.22390\t Validation loss: 0.14802\n",
      "[189] Training loss: 0.40849\t Validation loss: 0.64902\n",
      "[190] Training loss: 0.30960\t Validation loss: 0.42726\n",
      "[191] Training loss: 0.27226\t Validation loss: 0.39623\n",
      "[192] Training loss: 0.18804\t Validation loss: 0.40517\n",
      "[193] Training loss: 0.33378\t Validation loss: 0.11851\n",
      "[194] Training loss: 0.75655\t Validation loss: 0.39364\n",
      "[195] Training loss: 0.53706\t Validation loss: 1.21734\n",
      "[196] Training loss: 0.56620\t Validation loss: 0.42521\n",
      "[197] Training loss: 0.38996\t Validation loss: 0.12986\n",
      "[198] Training loss: 0.38833\t Validation loss: 1.10947\n",
      "[199] Training loss: 0.62577\t Validation loss: 0.65088\n",
      "[200] Training loss: 0.41130\t Validation loss: 0.58644\n",
      "[201] Training loss: 0.46703\t Validation loss: 1.32039\n",
      "[202] Training loss: 0.51601\t Validation loss: 0.69558\n",
      "[203] Training loss: 0.40164\t Validation loss: 0.93295\n",
      "[204] Training loss: 0.52377\t Validation loss: 0.52135\n",
      "[205] Training loss: 0.38557\t Validation loss: 1.03370\n",
      "[206] Training loss: 0.38251\t Validation loss: 0.28437\n",
      "[207] Training loss: 0.27904\t Validation loss: 0.19840\n",
      "[208] Training loss: 0.22832\t Validation loss: 0.08337\n",
      "[209] Training loss: 0.27919\t Validation loss: 0.70833\n",
      "[210] Training loss: 0.37273\t Validation loss: 0.57147\n",
      "[211] Training loss: 0.38191\t Validation loss: 0.26784\n",
      "[212] Training loss: 0.36630\t Validation loss: 0.29653\n",
      "[213] Training loss: 0.27110\t Validation loss: 0.44942\n",
      "[214] Training loss: 0.32758\t Validation loss: 0.53461\n",
      "[215] Training loss: 0.32651\t Validation loss: 0.54444\n",
      "[216] Training loss: 0.20670\t Validation loss: 0.60934\n",
      "[217] Training loss: 0.20030\t Validation loss: 0.19486\n",
      "[218] Training loss: 0.17668\t Validation loss: 0.13886\n",
      "[219] Training loss: 0.25574\t Validation loss: 0.23191\n",
      "[220] Training loss: 0.25511\t Validation loss: 0.30960\n",
      "[221] Training loss: 0.18556\t Validation loss: 0.14022\n",
      "[222] Training loss: 0.19620\t Validation loss: 0.45223\n",
      "[223] Training loss: 0.23634\t Validation loss: 0.08381\n",
      "[224] Training loss: 0.21790\t Validation loss: 0.08465\n",
      "[225] Training loss: 0.17318\t Validation loss: 0.15084\n",
      "[226] Training loss: 0.16902\t Validation loss: 0.22991\n",
      "[227] Training loss: 0.20323\t Validation loss: 0.06395\n",
      "[228] Training loss: 0.29804\t Validation loss: 0.29414\n",
      "[229] Training loss: 0.29443\t Validation loss: 0.25647\n",
      "[230] Training loss: 0.16146\t Validation loss: 0.44017\n",
      "[231] Training loss: 0.33624\t Validation loss: 0.25675\n",
      "[232] Training loss: 0.31045\t Validation loss: 0.08047\n",
      "[233] Training loss: 0.30990\t Validation loss: 0.54394\n",
      "[234] Training loss: 0.26945\t Validation loss: 0.10470\n",
      "[235] Training loss: 0.18584\t Validation loss: 0.17932\n",
      "[236] Training loss: 0.29916\t Validation loss: 0.67224\n",
      "[237] Training loss: 0.31802\t Validation loss: 0.23515\n",
      "[238] Training loss: 0.21306\t Validation loss: 0.24744\n",
      "[239] Training loss: 0.31298\t Validation loss: 1.56856\n",
      "[240] Training loss: 0.58040\t Validation loss: 2.12713\n",
      "[241] Training loss: 0.54889\t Validation loss: 0.99735\n",
      "[242] Training loss: 0.42596\t Validation loss: 0.48555\n",
      "[243] Training loss: 0.19713\t Validation loss: 0.14559\n",
      "[244] Training loss: 0.17141\t Validation loss: 0.04144\n",
      "[245] Training loss: 0.14822\t Validation loss: 0.12018\n",
      "[246] Training loss: 0.19891\t Validation loss: 0.28315\n",
      "[247] Training loss: 0.19979\t Validation loss: 0.12939\n",
      "[248] Training loss: 0.28715\t Validation loss: 0.28124\n",
      "[249] Training loss: 0.23745\t Validation loss: 0.34164\n",
      "[250] Training loss: 0.15238\t Validation loss: 0.33556\n"
     ]
    }
   ],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    batch_losses = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        batch_losses.append(loss)\n",
    "    training_loss = np.mean(batch_losses)\n",
    "    training_losses.append(training_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            model.eval()\n",
    "            yh = model(x_val)\n",
    "            #yh = torch.reshape(yh, (-1,))\n",
    "            val_loss = loss_fn(y_val, yh).item()\n",
    "            val_losses.append(val_loss)\n",
    "        validation_loss = np.mean(val_losses)\n",
    "        validation_losses.append(validation_loss)\n",
    "\n",
    "    print(f\"[{epoch+1}] Training loss: {training_loss:.5f}\\t Validation loss: {validation_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:05.620696Z",
     "start_time": "2023-02-23T12:27:05.618651Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:06.066552Z",
     "start_time": "2023-02-23T12:27:06.060567Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return torch.mean(torch.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:06.283526Z",
     "start_time": "2023-02-23T12:27:06.268573Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_tensor = x_test_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "y_pred = model(x_test_tensor).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:06.470029Z",
     "start_time": "2023-02-23T12:27:06.467036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3599, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_loss = loss_fn(y_test_tensor, y_pred)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:06.732368Z",
     "start_time": "2023-02-23T12:27:06.726385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of absolute percentage error for L1: 2.30%\n"
     ]
    }
   ],
   "source": [
    "print(f\"The mean of absolute percentage error: {mean_absolute_percentage_error(y_test_tensor.cpu(), y_pred.cpu()):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world case predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:11.660741Z",
     "start_time": "2023-02-23T12:27:11.465280Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:11.691218Z",
     "start_time": "2023-02-23T12:27:11.684269Z"
    }
   },
   "outputs": [],
   "source": [
    "case1 = pd.read_csv('Al-Sa-weidianzi.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:13.113614Z",
     "start_time": "2023-02-23T12:27:13.096259Z"
    }
   },
   "outputs": [],
   "source": [
    "case1 = np.reshape(np.array(case1), [ 1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:13.314202Z",
     "start_time": "2023-02-23T12:27:13.297249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:13.545266Z",
     "start_time": "2023-02-23T12:27:13.531249Z"
    }
   },
   "outputs": [],
   "source": [
    "case1= np.array(case1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:13.947059Z",
     "start_time": "2023-02-23T12:27:13.934088Z"
    }
   },
   "outputs": [],
   "source": [
    "case1_tensor = torch.from_numpy(case1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:14.300283Z",
     "start_time": "2023-02-23T12:27:14.290314Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred_1 = model(case1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T12:27:14.641191Z",
     "start_time": "2023-02-23T12:27:14.624232Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0304, 32.6180]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
